{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to load data into RedShift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_name='bankdemo_redshift_login' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q SQLAlchemy==1.3.13\n",
    "!pip install psycopg2-binary pyathena\n",
    "!pip install -U pip\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from pyathena import connect\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get region \n",
    "session = boto3.session.Session()\n",
    "region_name = session.region_name\n",
    "\n",
    "# Get SageMaker session & default S3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "redshift = boto3.client('redshift')\n",
    "secretsmanager = boto3.client('secretsmanager')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get credentials & connection information from Secret Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region\n",
    "    )\n",
    "\n",
    "try:\n",
    "    get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    secret_arn=get_secret_value_response['ARN']\n",
    "\n",
    "except ClientError as e:\n",
    "    print(\"Error retrieving secret. Error: \" + e.response['Error']['Message'])\n",
    "    \n",
    "else:\n",
    "    # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "    if 'SecretString' in get_secret_value_response:\n",
    "        secret = get_secret_value_response['SecretString']\n",
    "    else:\n",
    "        secret = base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "            \n",
    "secret_json = json.loads(secret)\n",
    "master_user_name = secret_json['username']\n",
    "master_user_pw = secret_json['password']\n",
    "redshift_port = secret_json['port']\n",
    "redshift_cluster_identifier = secret_json['dbClusterIdentifier']\n",
    "redshift_endpoint_address = secret_json['host']\n",
    "\n",
    "database_name_redshift = secret_json['database_name_redshift']\n",
    "database_name_athena = secret_json['database_name_athena']\n",
    "\n",
    "schema_redshift = secret_json['schema_redshift']\n",
    "schema_athena = secret_json['schema_athena']\n",
    "\n",
    "table_name_glue = secret_json['table_name_glue']\n",
    "table_name_redshift = secret_json['table_name_redshift']\n",
    "\n",
    "# print(master_user_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data (bank-additional.csv) to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file('bank-additional/bank-additional-full.csv', bucket, 'bankdemo/bank-additional.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Athena database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set S3 staging directory -- this is a temporary directory used for Athena queries\n",
    "s3_staging_dir = \"s3://{0}/athena/staging\".format(bucket)\n",
    "conn = connect(region_name=region_name, s3_staging_dir=s3_staging_dir)\n",
    "statement = \"CREATE DATABASE IF NOT EXISTS {}\".format(database_name_athena)\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_sql(statement, conn)\n",
    "statement = \"SHOW DATABASES\"\n",
    "\n",
    "df_show = pd.read_sql(statement, conn)\n",
    "df_show.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV to Athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'default' column name causes an error and I changed the name to 'defaulted' instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bankdemo_path = \"s3://{}/bankdemo/\".format(bucket)\n",
    "# SQL statement to execute\n",
    "statement = \"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS {}.{}(\n",
    "         age int,\n",
    "         job string,\n",
    "         marital string,\n",
    "         education string,\n",
    "         defaulted string,\n",
    "         housing string,\n",
    "         loan string,\n",
    "         contact string,\n",
    "         month string,\n",
    "         day_of_week string,\n",
    "         duration int,\n",
    "         campaign int,\n",
    "         pdays int,\n",
    "         previous int,\n",
    "         poutcome string,\n",
    "         emp_var_rate float,\n",
    "         cons_price_idx float,\n",
    "         cons_conf_idx float,\n",
    "         euribor3m float,\n",
    "         nr_employed int,\n",
    "         y string\n",
    ") \n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ',' \n",
    "LINES TERMINATED BY '\\n' \n",
    "LOCATION '{}'\n",
    "TBLPROPERTIES ('compressionType'='gzip', 'skip.header.line.count'='1')\"\"\".format(database_name_athena, table_name_glue, s3_bankdemo_path)\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_sql(statement, conn)\n",
    "statement = \"SHOW TABLES in {}\".format(database_name_athena)\n",
    "\n",
    "df_show = pd.read_sql(statement, conn)\n",
    "df_show.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test getting data from Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"SELECT * FROM {}.{}\n",
    "\"\"\".format(\n",
    "    database_name_athena, table_name_glue\n",
    ")\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(statement, conn)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedShift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to RedShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the cluster is available\n",
    "\n",
    "import time\n",
    "\n",
    "response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "print(cluster_status)\n",
    "\n",
    "while cluster_status != 'available':\n",
    "    time.sleep(10)\n",
    "    response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "    cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "    print(cluster_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the ApplyStatus is in-sync\n",
    "\n",
    "# redshift_endpoint_address = response['Clusters'][0]['Endpoint']['Address']\n",
    "iam_role = response['Clusters'][0]['IamRoles'][0]['IamRoleArn']\n",
    "\n",
    "response['Clusters'][0]['IamRoles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Redshift endpoint: {}'.format(redshift_endpoint_address))\n",
    "print('IAM Role: {}'.format(iam_role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(master_user_name, master_user_pw, redshift_endpoint_address, redshift_port, database_name_redshift))\n",
    "session = sessionmaker()\n",
    "session.configure(bind=engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RedShift schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"CREATE SCHEMA IF NOT EXISTS {}\"\"\".format(schema_redshift)\n",
    "\n",
    "s = session()\n",
    "s.execute(statement)\n",
    "s.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Athena Database bankdemo with Redshift Spectrum to Access the Data Directly in S3 using Glue Data Catalog\n",
    "\n",
    "With just one command, you can query the S3 data lake from Amazon Redshift without moving any data into our data warehouse. This is the power of Redshift Spectrum. \n",
    "\n",
    "Note the `FROM DATA CATALOG` below.  This is pulling the table and schema information from the Glue Data Catalog (ie. Hive Metastore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "CREATE EXTERNAL SCHEMA IF NOT EXISTS {} FROM DATA CATALOG \n",
    "    DATABASE '{}' \n",
    "    IAM_ROLE '{}'\n",
    "    REGION '{}'\n",
    "    CREATE EXTERNAL DATABASE IF NOT EXISTS\n",
    "\"\"\".format(schema_athena, database_name_athena, iam_role, region_name)\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = session()\n",
    "s.execute(statement)\n",
    "s.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Sample Query on S3 Data through Redshift Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT *\n",
    "    FROM {}.{}\n",
    "\"\"\".format(schema_athena, table_name_glue)\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(statement, engine)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table in RedShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {}.{}( \n",
    "     age integer,\n",
    "     job text,\n",
    "     marital text,\n",
    "     education text,\n",
    "     defaulted text,\n",
    "     housing text,\n",
    "     loan text,\n",
    "     contact text,\n",
    "     month text,\n",
    "     day_of_week text,\n",
    "     duration integer,\n",
    "     campaign integer,\n",
    "     pdays integer,\n",
    "     previous integer,\n",
    "     poutcome text,\n",
    "     emp_var_rate decimal,\n",
    "     cons_price_idx decimal,\n",
    "     cons_conf_idx decimal,\n",
    "     euribor3m decimal,\n",
    "     nr_employed integer,\n",
    "     y text\n",
    "     )\n",
    "\"\"\".format(schema_redshift, table_name_redshift)\n",
    "\n",
    "print(statement)\n",
    "s = session()\n",
    "s.execute(statement)\n",
    "s.commit()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data from S3 to RedShift using Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "INSERT INTO {}.{}\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        {}.{};             \n",
    "\n",
    "\"\"\".format(schema_redshift, table_name_redshift, schema_athena, table_name_glue)\n",
    "print(statement)\n",
    "s = session()\n",
    "s.execute(statement)\n",
    "s.commit()        \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test getting data from RedShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT *\n",
    "    FROM {}.{}\n",
    "\"\"\".format(schema_redshift, table_name_redshift)\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(statement, engine)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
