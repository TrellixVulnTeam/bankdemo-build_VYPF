{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random predictions to SageMaker endpoint\n",
    "\n",
    "**Note:** Please set kernel to `Python 3 (Data Science)`\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ”¥ Note: Before running this notebook, ensure that notebook 03 ran successfully and the updated files were committed to CodeCommit. Also, ensure the SageMaker Pipeline execution is successful and the staging endpoint shows `InService`. You can check the endpoint status in the SageMaker project page, under the Endpoints tab. ðŸ”¥\n",
    "\n",
    "In the screenshot below, my project name is `BankDM` and the endpoint is `BankDM-staging`.\n",
    "\n",
    "![endpoint](img/check-endpoint1.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Now that the model is trained and deployed, the next step is to use the model to do predictions. You will first connect to RedShift and retrieve the data. For simplicity, this demo uses data that is already stored in RedShift and the same data was used to do training/testing. In real world, the data used for prediction should not be seen before by the model. Before doing predictions, you need to do preprocessing of the data to ensure it is of the same format as the training data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "Variable name for secret in Secret Manager and SageMaker endpoint. RedShift, Athena and Glue information are stored in the secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_name='bankdm_redshift_login' \n",
    "\n",
    "# The endpoint name below is the default based on the SageMaker project name\n",
    "# endpoint name is case sensitive\n",
    "endpoint_name = 'BankDM-staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q SQLAlchemy==1.3.13\n",
    "!pip install psycopg2-binary pyathena\n",
    "!pip install -U pip\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from pyathena import connect\n",
    "from botocore.exceptions import ClientError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create client session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get region \n",
    "session = boto3.session.Session()\n",
    "region_name = session.region_name\n",
    "\n",
    "# Get SageMaker session & default S3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "redshift = boto3.client('redshift')\n",
    "secretsmanager = boto3.client('secretsmanager')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get credentials & connection information from Secret Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_secret_value_response = secretsmanager.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    secret_arn=get_secret_value_response['ARN']\n",
    "\n",
    "except ClientError as e:\n",
    "    print(\"Error retrieving secret. Error: \" + e.response['Error']['Message'])\n",
    "    \n",
    "else:\n",
    "    # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "    if 'SecretString' in get_secret_value_response:\n",
    "        secret = get_secret_value_response['SecretString']\n",
    "    else:\n",
    "        secret = base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "            \n",
    "secret_json = json.loads(secret)\n",
    "master_user_name = secret_json['username']\n",
    "master_user_pw = secret_json['password']\n",
    "redshift_port = secret_json['port']\n",
    "redshift_cluster_identifier = secret_json['dbClusterIdentifier']\n",
    "redshift_endpoint_address = secret_json['host']\n",
    "\n",
    "database_name_redshift = secret_json['database_name_redshift']\n",
    "database_name_glue = secret_json['database_name_glue']\n",
    "\n",
    "schema_redshift = secret_json['schema_redshift']\n",
    "schema_athena = secret_json['schema_athena']\n",
    "\n",
    "table_name_glue = secret_json['table_name_glue']\n",
    "table_name_redshift = secret_json['table_name_redshift']\n",
    "\n",
    "# print(master_user_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RedShift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to RedShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "iam_role = response['Clusters'][0]['IamRoles'][0]['IamRoleArn']\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(master_user_name, master_user_pw, redshift_endpoint_address, redshift_port, database_name_redshift))\n",
    "session = sessionmaker()\n",
    "session.configure(bind=engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from RedShift and shuffle it\n",
    "As mentioned earlier, for simplicity, the data is the same as the one used for training/testing purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = f\"\"\"\n",
    "select *  \n",
    "    FROM {schema_redshift}.{table_name_redshift} order by random()\n",
    "\"\"\"\n",
    "\n",
    "# print(statement)\n",
    "\n",
    "data = pd.read_sql_query(statement, engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['no_previous_contact'] = np.where(data['pdays'] == 999, 1, 0)                                 # Indicator variable to capture when pdays takes a value of 999\n",
    "data['not_working'] = np.where(np.in1d(data['job'], ['student', 'retired', 'unemployed']), 1, 0)   # Indicator for individuals not actively employed\n",
    "model_data = pd.get_dummies(data)                                                                  # Convert categorical variables to sets of indicators\n",
    "\n",
    "model_data = model_data.drop(['duration', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m'], axis=1)\n",
    "df = pd.concat([model_data['y_yes'], model_data.drop(['y_no', 'y_yes'], axis=1)], axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract out the target column to another dataframe and drop the column in the existing dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_yes = df['y_yes']\n",
    "df = df.drop(['y_yes'], axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the target value dataframe is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_yes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_test =df[df.columns[:]].values\n",
    "arr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name)\n",
    "predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select a user and predicts\n",
    "i = random.randint(1, len(arr_test)) \n",
    "print(i)\n",
    "pred = predictor.predict(arr_test[:][i])\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the actual result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual value\n",
    "df_y_yes[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare if the pred and actual result are similar with a tolerance of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.isclose(float(pred), df_y_yes[i], abs_tol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Now that prediction using a SageMaker endpoint works, the next step is to use RedShift ML to do prediction as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
