{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the foundation\n",
    "\n",
    "**Note:** Please set kernel to `Python 3 (Data Science)`\n",
    "\n",
    "Before proceeding, please read the **README.md** and complete the prerequisite first.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of AWS services used in this notebook\n",
    "\n",
    "Amazon SageMaker is a fully managed machine learning service. With SageMaker, data scientists and developers can quickly and easily build and train machine learning models, and then directly deploy them into a production-ready hosted environment.\n",
    "\n",
    "Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. With Redshift, you can query and combine exabytes of structured and semi-structured data across your data warehouse, operational database, and data lake using standard SQL. Redshift lets you easily save the results of your queries back to your S3 data lake using open formats, like Apache Parquet, so that you can do additional analytics from other analytics services like Amazon EMR, Amazon Athena, and Amazon SageMaker. Many customers use RedShift as their data warehouse and it could be one of data source for customers doing machine learning.\n",
    "\n",
    "AWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources. The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Users and applications retrieve secrets with a call to Secrets Manager APIs, eliminating the need to hardcode sensitive information in plain text.\n",
    "\n",
    "AWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers, creating workload-aware cluster scaling logic, maintaining event integrations, or managing runtimes. With Lambda, you can run code for virtually any type of application or backend service - all with zero administration. Just upload your code as a ZIP file or container image, and Lambda automatically and precisely allocates compute execution power and runs your code based on the incoming request or event, for any scale of traffic.\n",
    "\n",
    "AWS Identity and Access Management (IAM) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This series of notebooks demostrate a MLOps workflow where the data source is from RedShift. RedShift ML is also shown where you can train and use a model directly from RedShift. More information regarding the setup can be found in the [README.md](README.md) file.\n",
    "\n",
    "### High-level architecture diagram\n",
    "The diagram below shows the architecture diagram at this point in time (not final).\n",
    "\n",
    "![diagram](img/diagram1.png)\n",
    "\n",
    "In this notebook, you create the foundation components - IAM roles, policies, RedShift cluster, secret in Secret Manager and lambda.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "Variable names for secret, RedShift, Athena and Glue.\n",
    "\n",
    "Most of the information below are stored in the secret and you will retrieve them in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_name='bankdm_redshift_login' \n",
    "\n",
    "# Random function to generate password.\n",
    "import random\n",
    "import string\n",
    "def random_char(y):\n",
    "       return ''.join(random.choice(string.ascii_letters) for x in range(y))\n",
    "    \n",
    "# The variables below are only required for notebook 01\n",
    "# The RedShift, Athena and Glue information are stored in Secrets Manager\n",
    "subnet_name = 'Private subnet' # Change this is the private subnet name is different\n",
    "\n",
    "database_name_redshift = 'bankdm'\n",
    "database_name_glue = 'bankdm'\n",
    "\n",
    "schema_redshift = 'dm'\n",
    "schema_athena = 'athena' # have to be athena\n",
    "\n",
    "table_name_glue = 'bankdm_glue'\n",
    "table_name_redshift = 'data'\n",
    "\n",
    "\n",
    "# Redshift configuration parameters\n",
    "redshift_cluster_identifier = 'bankdm'\n",
    "database_name = 'bankdm'\n",
    "cluster_type = 'single-node' # or multi-node\n",
    "\n",
    "master_user_name = 'bankdm'\n",
    "master_user_pw = random_char(16) + '1' # the password requires a number\n",
    "\n",
    "# Note that only some Instance Types support Redshift Query Editor \n",
    "# (https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor.html)\n",
    "node_type = 'dc2.large'\n",
    "# number_nodes = '1' # for multi-node. Also uncomment this line below: NumberOfNodes=int(number_nodes),\n",
    "\n",
    "# Set the security group ID if not using the default one\n",
    "security_group_id = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries and create client sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore.config import Config\n",
    "import time\n",
    "import sagemaker\n",
    "import zipfile\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "sts = boto3.client('sts')\n",
    "accountID = sts.get_caller_identity()[\"Account\"]  \n",
    "redshift = boto3.client('redshift')\n",
    "sm = boto3.client('sagemaker')\n",
    "ec2 = boto3.client('ec2')\n",
    "secretsmanager = boto3.client('secretsmanager')\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAM Roles and Policy\n",
    "### Adding permissions to SageMaker Execution role\n",
    "This should already be done by the CloudFormation template but it doesn't hurt to check this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = role.split(\"/\")[-1]\n",
    "\n",
    "print(\"Role name: {}\".format(role_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_policies = iam.list_attached_role_policies(RoleName=role_name)[\"AttachedPolicies\"]\n",
    "\n",
    "required_policies = [\"IAMFullAccess\"]\n",
    "\n",
    "for pre_policy in pre_policies:\n",
    "    for role_req in required_policies:\n",
    "        if pre_policy[\"PolicyName\"] == role_req:\n",
    "            print(\"Attached: {}\".format(pre_policy[\"PolicyName\"]))\n",
    "            try:\n",
    "                required_policies.remove(pre_policy[\"PolicyName\"])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "if len(required_policies) > 0:\n",
    "    print(\n",
    "        \"*************** [ERROR] You need to attach the following policies in order to continue with this workshop *****************\\n\"\n",
    "    )\n",
    "    for required_policy in required_policies:\n",
    "        print(\"Not Attached: {}\".format(required_policy))\n",
    "else:\n",
    "    print(\"[OK] You are all set to continue with this notebook!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to add policy to the role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPolicy(policy, role_name):\n",
    "    try:\n",
    "        response = iam.attach_role_policy(PolicyArn=\"arn:aws:iam::aws:policy/{}\".format(policy), RoleName=role_name)\n",
    "        print(\"Policy {} has been succesfully attached to role: {}\".format(policy, role_name))\n",
    "    except ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":\n",
    "            print(\"[OK] Policy is already attached.\")\n",
    "        elif e.response[\"Error\"][\"Code\"] == \"LimitExceeded\":\n",
    "            print(\"[OK]\")\n",
    "        else:\n",
    "            print(\"*************** [ERROR] {} *****************\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the following policies to the role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addPolicy(\"AmazonRedshiftFullAccess\", role_name)\n",
    "addPolicy(\"SecretsManagerReadWrite\", role_name)\n",
    "addPolicy(\"AmazonAthenaFullAccess\", role_name)\n",
    "# The Lambda role is needed to create the lambda function below\n",
    "addPolicy(\"AWSLambda_FullAccess\", role_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the following policies to SageMaker ServiceCatalog role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servicerole = 'AmazonSageMakerServiceCatalogProductsUseRole'\n",
    "addPolicy(\"AmazonSageMakerPipelinesIntegrations\", servicerole)\n",
    "# The Lambda role is required to create lambda function in the SageMaker Pipeline. \n",
    "# However, this portion of the code is commented out.\n",
    "addPolicy(\"AWSLambda_FullAccess\", servicerole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add permissions to BankDM role\n",
    "#### Create AssumeRolePolicyDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = f\"arn:aws:iam::{accountID}:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\"\n",
    "assume_role_policy_doc = {\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"AWS\": role,\n",
    "        \"Service\": [\"sagemaker.amazonaws.com\", \"redshift.amazonaws.com\"]\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "assume_role_policy_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_redshift_role_name = 'BankDM-RedShift'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    iam_role_redshift = iam.create_role(\n",
    "        RoleName=iam_redshift_role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_doc),\n",
    "        Description='BankDM Redshift Role'\n",
    "    )\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        print(\"Role already exists\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Role ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = iam.get_role(RoleName=iam_redshift_role_name)\n",
    "iam_role_redshift_arn = role['Role']['Arn']\n",
    "print(iam_role_redshift_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach AWS built-in policy to role\n",
    "Note: The CloudFormation should have added the below policy but to be safe, the script adds them again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addPolicy(\"SecretsManagerReadWrite\", iam_redshift_role_name)\n",
    "addPolicy(\"AmazonRedshiftFullAccess\", iam_redshift_role_name)\n",
    "addPolicy(\"AmazonSageMakerFullAccess\", iam_redshift_role_name)\n",
    "addPolicy(\"AmazonS3FullAccess\", iam_redshift_role_name)\n",
    "addPolicy(\"AmazonAthenaFullAccess\", iam_redshift_role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RedShift cluster\n",
    "### Get Security Group ID \n",
    "\n",
    "* Make sure the VPC used by RedShift is the same this notebook is running within\n",
    "* Make sure the VPC has the following 2 properties enabled\n",
    " *     DNS resolution = Enabled\n",
    " *     DNS hostnames = Enabled\n",
    "* This allows private, internal access to Redshift from this SageMaker notebook using the fully qualified endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if security_group_id is None:\n",
    "    try:\n",
    "        domain_id = sm.list_domains()['Domains'][0]['DomainId'] #['NotebookInstances'][0]['NotebookInstanceName']\n",
    "        describe_domain_response = sm.describe_domain(DomainId=domain_id)\n",
    "        vpc_id = describe_domain_response['VpcId']\n",
    "        security_groups = ec2.describe_security_groups(Filters=[{\"Name\": \"vpc-id\", \"Values\": [vpc_id]}])['SecurityGroups']\n",
    "        security_group_id = ''\n",
    "\n",
    "        for sg in security_groups:\n",
    "            if(sg['GroupName'] == 'default'):\n",
    "                security_group_id = sg['GroupId']\n",
    "\n",
    "        print(security_group_id)    \n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subnet for RedShift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the subnet ID for the private subnet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_all = ec2.describe_subnets(Filters=[{\"Name\": \"vpc-id\", \"Values\": [vpc_id]}])\n",
    "subnetId = ''\n",
    "for sn in sn_all['Subnets'] :\n",
    "    for tags in sn['Tags'] :\n",
    "#         print(tags)\n",
    "        if(tags['Key'] == 'Name' and tags['Value'] == subnet_name):\n",
    "           subnetId = sn['SubnetId']\n",
    "subnetId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_all['Subnets'][0]['Tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Redshift Cluster\n",
    "Create the RedShift subnet group and after that, create the RedShift cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster_subnet_group(\n",
    "        ClusterSubnetGroupName='bankdm-subnet',\n",
    "        Description='string',\n",
    "        SubnetIds=[\n",
    "            subnetId,\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ClusterSubnetGroupAlreadyExists':\n",
    "        print(\"Cluster subnet group already exists. This is ok.\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(\n",
    "            DBName=database_name,\n",
    "            ClusterIdentifier=redshift_cluster_identifier,\n",
    "            ClusterType=cluster_type,\n",
    "            NodeType=node_type,\n",
    "    #         NumberOfNodes=int(number_nodes),       # This is required if multi-node is specified\n",
    "            ClusterSubnetGroupName='bankdm-subnet',\n",
    "            MasterUsername=master_user_name,\n",
    "            MasterUserPassword=master_user_pw,\n",
    "            IamRoles=[iam_role_redshift_arn],\n",
    "            VpcSecurityGroupIds=[security_group_id],\n",
    "            Port=5439,\n",
    "            PubliclyAccessible=False\n",
    "    )\n",
    "    \n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ClusterAlreadyExists':\n",
    "        print(\"Cluster already exists. This is ok.\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please Wait for Cluster Status to change to `Available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "print(cluster_status)\n",
    "\n",
    "while cluster_status != 'available':\n",
    "    time.sleep(10)\n",
    "    response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "    cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "    print(cluster_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "host = response['Clusters'][0]['Endpoint']['Address']\n",
    "port = response['Clusters'][0]['Endpoint']['Port']\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Secret in Secrets Manager\n",
    "\n",
    "Add RedShift, Athena and Glue information to the secret. \n",
    "\n",
    "Note: If the secret already exists and you are creating the RedShift cluster again, the secret will not be updated to the new password. Please update the password manually in Secrets Manager.\n",
    "This is to prevent accidential update to the secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secretstring = f'\"username\":\"{master_user_name}\",\"password\":\"{master_user_pw}\",\"engine\":\"redshift\", \\\n",
    "\"host\":\"{host}\",\"port\": \"{port}\",\"dbClusterIdentifier\":\"{redshift_cluster_identifier}\", \"db\":\"{database_name}\", \\\n",
    "\"database_name_redshift\":\"{database_name_redshift}\",\"database_name_glue\": \"{database_name_glue}\", \\\n",
    "\"schema_redshift\":\"{schema_redshift}\", \"schema_athena\":\"{schema_athena}\", \\\n",
    "\"table_name_glue\":\"{table_name_glue}\", \"table_name_redshift\":\"{table_name_redshift}\"'\n",
    "\n",
    "secretstring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = secretsmanager.create_secret(\n",
    "        Name=secret_name,\n",
    "        Description='BankDM Redshift Login',\n",
    "        SecretString= '{' + secretstring + '}',\n",
    "    )\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceExistsException':\n",
    "        print(\"Secret already exists. If you are recreating the RedShift cluster, please update the password manually in Secrets Manager.\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lambda IAM role and policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lambda_role(role_name):\n",
    "    try:\n",
    "        response = iam.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps({\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": \"lambda.amazonaws.com\"\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\"\n",
    "                    }\n",
    "                ]\n",
    "            }),\n",
    "            Description='Role for Lambda'\n",
    "        )\n",
    "\n",
    "        role_arn = response['Role']['Arn']\n",
    "\n",
    "        response = iam.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "        )\n",
    "\n",
    "        addPolicy(\"SecretsManagerReadWrite\", role_name)\n",
    "        addPolicy(\"AmazonRedshiftFullAccess\", role_name)\n",
    "        addPolicy(\"AmazonSageMakerFullAccess\", role_name)\n",
    "        addPolicy(\"AmazonS3FullAccess\", role_name)\n",
    "        \n",
    "        return role_arn\n",
    "\n",
    "    except iam.exceptions.EntityAlreadyExistsException:\n",
    "        print(f'Using ARN from existing role: {role_name}')\n",
    "        response = iam.get_role(RoleName=role_name)\n",
    "        return response['Role']['Arn']\n",
    "\n",
    "lambda_role = create_lambda_role(\"BankDM-Lambda\")\n",
    "\n",
    "# Have to wait a little before creating the lambda\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip up the lambda code\n",
    "archive = zipfile.ZipFile('lambda.zip', 'w')\n",
    "archive.write('lambda_redshift_dl.py', 'lambda_redshift_dl.py')\n",
    "archive.close()\n",
    "\n",
    "# Upload the file to S3\n",
    "s3.upload_file('lambda.zip', bucket, 'bankdm/lambda.zip')\n",
    "\n",
    "# Delete the lambda function if it exists\n",
    "try:\n",
    "    response = lambda_client.delete_function(\n",
    "            FunctionName='bankdm-redshift-dl',\n",
    "        )\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "        print(\"Lambda function not found. Creating it...\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e) \n",
    "\n",
    "# Create the lambda function\n",
    "try:\n",
    "    response = lambda_client.create_function(\n",
    "                Code={\n",
    "                    'S3Bucket': bucket,\n",
    "                    'S3Key': 'bankdm/lambda.zip', \n",
    "                },\n",
    "                FunctionName='bankdm-redshift-dl',\n",
    "                Handler='lambda_redshift_dl.lambda_handler',\n",
    "                Publish=True,\n",
    "                Role=lambda_role,\n",
    "                Runtime='python3.8',\n",
    "                Timeout=600, # Set to 10 minutes\n",
    "                MemorySize=512,\n",
    "            )\n",
    "except ClientError as e:\n",
    "    print(\"Unexpected error: %s\" % e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Now that you have created the foundation layer (IAM roles, policies, secret manager, RedShift cluster, lambda), you can proceed to explore the data (notebook 02 - optional) or you can choose to insert data into RedShift (notebook 03)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
